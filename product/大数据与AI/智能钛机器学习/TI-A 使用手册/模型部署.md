训练好的模型可以作为一个服务对外部署，使模型快速投入使用。

## 部署服务

*MNIST For ML Beginner* 例子中，训练后存储在 COS 的模型可以作为服务直接部署：

```bash
$ tictl model create mnist-model \
  --description=mnist-model \
  --model="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/mnist_example:/data/mnist"

create model success.
NAME           CREATED                          URL    STATE    MESSAGE
mnist-model    2018-05-04 13:49:52 +0800 CST                    creating
```

查看模型服务部署状态：

```bash
$ tictl model list
NAME           CREATED                          URL                STATE      MESSAGE
mnist-model    2018-05-04 13:49:52 +0800 CST    193.112.231.182    Running    Deployment has minimum availability.
```

从 URL 字段我们看到服务对外暴露的 IP，同时暴露的还有 80(http) 和9000(rpc) 端口。

## 测试服务是否部署成功

这里我们使用例子中的测试脚本测试服务（目前还在 beta 阶段，如果环境准备有困难，请跳过此部分）：

#### 环境准备

[安装 TensorFlow](https://tensorflow.google.cn/install/)

安装 Serving API:

```bash
$ pip install tensorflow-serving-api
```

#### 查看测试结果

> 注意：这里需要将 mnist_client.py 文件中的 model 名称改为之前创建的模型名，这里即为 mnist-model

```bash
$ python mnist_client.py --num_tests=100 --server=193.112.231.182:9000
...
Inference error rate: 7.0%
```

恭喜，现在你已经会用 `tictl` 来部署一个服务了！
