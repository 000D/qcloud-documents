在开始训练之前，您需要了解使用 TI-A 平台的一般工作流：

1. 在本地利用小规模数据集，调通训练模型的程序；
2. 将本地准备好的数据和程序上传到我们的对象存储（COS）中；
3. 利用 `tictl` 工具，充分利用 TI-A 平台支持的 **单机/分布式**，**CPU/GPU** 等多种能力，高效省心地完成训练；
4. 可选直接部署模型，对外提供服务。

## 示例一：单机训练任务
### 准备数据

这里采用 [MNIST For ML Beginner](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/example/mnist_saved_model.py) 的 TensorFlow 程序作为示例。

1.使用 `coscmd` 将示例下载到本地，来作为本地准备好的程序：

```bash
$ coscmd -b tia-demo-1255502019 -r ap-shanghai download -r mnist_example mnist_example
```

2.在 `mnist_example` 文件夹所在目录，使用 coscmd 将上述示例上传到同样名为 `mnist_example` 的 COS 目录下：

```bash
$ coscmd upload -r mnist_example mnist_example
upload mnist_example/mnist_client.py   =>   cos://mybucket/mnist_example/mnist_client.py  [100%]
upload mnist_example/mnist_input_data.py   =>   cos://mybucket/mnist_example/mnist_input_data.py  [100%]
upload mnist_example/mnist_saved_model.py   =>   cos://mybucket/mnist_example/mnist_saved_model.py  [100%]
1 folders, 3 files successful, 0 files failed
```

### 开启使用 CPU 的单机任务

利用 `tictl` 来开启训练任务，只需执行下面的命令：

> **注意：**
> job 命名只能使用小写字母、数字、以及 ‘.’ 和 ‘-’ 的组合，且开头必须是小写字母或者数字。

```bash
$ tictl job create cpu-job \
  --packagedir="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/mnist_example:/data/mnist_example" \
  --command=python \
  --args="mnist_saved_model.py cpu_model" \
  --runtime=tia-1.6.0

create job success.
NAME       CREATED                                                       END    STATE    MESSAGE
cpu-job    2018-05-03 20:06:40.109664331 +0800 CST m=+16304.376036037                    creating
```

#### 参数说明

- **--packagedir：**由 `程序来源` 和 `加载路径` 两部分组成，由 ‘：’ 连接

  - **程序来源：**要执行的代码所在的 COS 目录路径，即为桶的请求域名加上文件夹路径，参考 [安装对象存储工具（coscmd）](#安装对象存储工具（coscmd）)。上例中，即为：`cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/mnist_example`.
  
  - **加载路径：**运行时程序要加载到的目录路径名，即为用户的工作目录。上例中，即为：`/data/mnist_example`。
  
- **--command：**运行脚本所需的命令或程序。
- **--args：**开启训练需要的参数。
  - **mnist_saved_model.py：**第一个参数，是被执行的程序脚本文件。
  
  - **cpu_model：**第二个以及之后的参数，是程序脚本自身需要的参数，本例中的参数指定的是导出模型的存放地址。
- **--runtime：**由 TI-A 平台提供好的程序的运行环境，带有不同的标签，对应不同的环境。

## 示例二：分布式训练任务
TI-A 平台同时支持运行分布式任务（目前仅支持 TensorFlow 中的 Estimator 模式），这里使用 [Custom Estimator](https://github.com/GoogleCloudPlatform/cloudml-samples/tree/master/census/estimator/trainer) 作为例子。

1.使用 `coscmd` 将示例下载到本地，来作为我们本地准备好的程序：

```bash
$ coscmd -b tia-demo-1255502019 -r ap-shanghai download -r estimator estimator
```
2.在 `estimator`文件夹所在目录，我们使用 `coscmd` 把它上传到同样名为 `estimator` 的 COS 目录下：

```bash
$ coscmd upload -r estimator estimator
```

3.运行以下命令，开启分布式训练：

```bash
$ tictl job create dist-job \
  --packagedir="cos://mybucket-1256385809.cos.ap-shanghai.myqcloud.com/estimator:/estimator" \
  --command=python \
  --args="-m trainer.task \
          --job-dir output \
          --train-files /estimator/data/adult.data.csv \
          --eval-files /estimator/data/adult.test.csv \
          --train-steps 1000 \
          --eval-steps 100" \
  --mt=2U4G0P \
  --wt=2U4G0P \
  --pt=2U4G0P \
  --pscount=2 \
  --wcount=2

create job success.
NAME        CREATED                                                       END    STATE    MESSAGE
dist-job    2018-05-03 21:17:00.907763737 +0800 CST m=+20525.174135470                    creating
```
#### 参数说明

- **--mt：**即 master type，用以指定 master 节点的机型配置。
- **--wt：**即 worker type，用以指定 worker 节点的机型配置。
- **--pt：**即 ps type，用以指定 parameter server 节点的机型配置。
- **--pscount：**parameter server 节点的个数。
- **--wcount：**worker 节点的个数。

现在，您已经会用 `tictl` 来指定使用 CPU 或者 GPU 来开启单机或者分布式的训练任务了！

