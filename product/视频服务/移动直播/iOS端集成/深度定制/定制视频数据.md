## 定制视频数据
研发实力不俗的客户，会有自定义图像处理的需求（比如堆加字幕），同时又希望复用rtmp sdk的整体流程，如果是这样，您可以按照如下攻略进行定制。

- **设置视频处理回调**
设置 **TXLivePush** 的 **videoProcessDelegate** 代理点，即可实现对视频画面的定制。

```objectivec
@protocol TXVideoCustomProcessDelegate <NSObject>

/**
 * 在OpenGL线程中回调，在这里可以进行采集图像的二次处理
 * @param textureId  纹理ID
 * @param width      纹理的宽度
 * @param height     纹理的高度
 * @return           返回给SDK的纹理
 * 说明：SDK回调出来的纹理类型是 GL_TEXTURE_2D，接口返回给SDK的纹理类型也必须是 GL_TEXTURE_2D
 */
-(GLuint)onPreProcessTexture:(GLuint)texture width:(CGFloat)width height:(CGFloat)height;
 
/**
 * 在OpenGL线程中回调，可以在这里释放创建的OpenGL资源
 */
-(void)onTextureDestoryed;

@end
```

- **在回调函数中对视频数据进行加工**
实现 TXVideoCustomProcessDelegate 的 onTextureCustomProcess 函数，以实现对视频画面的自定义处理。textureId 指定的纹理是一块类型为 GLES20.GL_TEXTURE_2D 的纹理。

 对于 texture 数据的操作，需要一定的 OpenGL 基础知识，另外计算量不宜太大，因为 onTextureCustomProcess 的调用频率跟 FPS 相同，过于繁重的处理很容易造成 GPU 过热。


## 自己采集数据
如果您只希望使用 SDK 来编码和推流（比如已经对接了商汤等产品），音视频采集和预处理（即美颜、滤镜这些）全部由自己的代码来控制，可以按如下步骤实现：

- **Step1. 不再调用 TXLivePush 的 startPreview 接口**
这样 SDK 本身就不会再采集视频数据和音频数据，而只是启动预处理、编码、流控、发送 等跟推流相关的工作

- **Step2. 使用 sendVideoSampleBuffer 向SDK填充Video数据**
sendVideoSampleBuffer 的作用是向 SDK 塞入您采集和处理后的视频数据，目前支持 RGBA 和 NV12 两种格式。

- **Step3. 使用 sendAudioSampleBuffer 向SDK填充Audio数据**
sendAudioSampleBuffer 的作用是向 SDK 塞入您采集和处理后的音频数据，请使用单声道、16位宽、48000Hz 的 PCM  声音数据。
