
> Note: Since the APIs of RTMP SDK are highly similar on the two platforms, only the version of Objective-C is provided for all the example codes in this document. This also aims to reduce the document length.

## 1. Principle techniques of RTMP SDK
The figure below shows the principle techniques of the RTMP SDK of Tencent Cloud:
- **Step1 - Starting point of invoking: After startPush of the **TXLivePush object is invoked, the push process will be started.

- **Step2 - Connecting to the server: **The first step of push is to try to connect to the server. If it fails, the NET_DISCONNECT error is thrown, instead of continuing execution of the subsequent process.

- **Step3 - Starting pushing: **PUSH_EVT_PUSH_BEGIN indicates that push truly starts. Many customers wrongly deem that push starts successfully after startPush is invoked, but it is not the truth.

- **step4 - Main loop of push: **Push of LVB is an ongoing process, driven by a main loop engine in the SDK. The main loop will jump only when the process is stopped actively using stopPush or it suffers an irrecoverable error.

![Principle techniques of SDK](http://qzonestyle.gtimg.cn/qzone/vas/opensns/res/img/tencent_cloud_rtmp_sdk_pusher_status_14.jpg)

## 2. Learning the push quality of SDK
Measures were taken to avoid excessive closeness when the RTMP SDK was just designed, making you feel that we do not hope that the SDK is a blacklist completely. Therefore, we provide a kind of **state feedback mechanism**: all the state parameters will be reported every 1s to 2s.

![](//mc.qcloudimg.com/static/img/48fd46af4e17b0299fd00a0e661a16f0/image.png)

You need to provide a **TXLivePushListener** to the TXLivePush object. The RTMP SDK will inform the outside of all the internal states through onNetStatus callback.
  
|  Push status                   |  Description                    |   
| :------------------------  |  :------------------------ | 
| NET_STATUS_CPU_USAGE | CPU utilization for the current process and overall CPU utilization for the machine |
| NET_STATUS_VIDEO_WIDTH | Width of the current video (in pixels) |
| NET_STATUS_VIDEO_HEIGHT | Height of the current video (in pixels) |
| NET_STATUS_NET_SPEED | Current transmission speed in kbps |
| NET_STATUS_VIDEO_BITRATE | Output bit rate of the current video encoder (kbps)|
| NET_STATUS_AUDIO_BITRATE | Output bit rate of the current audio encoder (unit: kbps)|
| NET_STATUS_VIDEO_FPS | Current video frame rate (frames per second)|
| NET_STATUS_CACHE_SIZE | Audio/video data accumulated. If this value exceeds 10, it means that the current uplink bandwidth is not enough to consume audio/video data produced |
| NET_STATUS_CODEC_DROP_CNT | The number of global packet losses. In order to avoid the continued severe accumulation of packets, the SDK begins to actively discard packets after the warning line is reached. The more packets are lost, the severer network problems are. |
| NET_STATUS_SERVER_IP | IP of the push server |
| NET_STATUS_NET_JITTER | Network jitter |

### 2.1 Judgment of Push Quality
The following are several judgment criteria that we often use.

**1. BITRATE and NET_SPEED**
> BITRATE(= VIDEO_BITRATE + AUDIO_BITRATE) refers to how much audio/video data the encoder produces per second. NET_SPEED refers to how much audio/video data the encoder actually pushes per second. Therefore, if BITRATE equals to NET_SPEED consequently, the push quality will be good.
>
>And if the BITRATE >= NET_SPEED, then push quality is poor.

**2. CACHE_SIZE and DROP_CNT**
> If BITRATE> = NET_SPEED, the audio/video data generated by the encoder will be accumulated in the VJ's phone. The severity is indicated by the value of CACHE_SIZE. When the CACHE_SIZE value reaches a threshold, SDK will automatically discard some audio/video data, which will increase DROP_CNT.
>
> If CACHE_SIZE value stays over 10, or DROP_CNT value increases, it indicates that the VJ's network condition is poor and the push quality may be affected.
>
>See below for an example of <font color='blue'> video lagging caused by insufficient uplink bandwidth</font>:
>![](//mc.qcloudimg.com/static/img/319d6197da603ca15ffc6e2afd778e48/image.png)

**3. CPU_USAGE** 
> RTMP SDK keeps the CPU usage for push below 50%, especially when hardware coding is enabled. For example, on Xiaomi 3, when hardware acceleration is enabled, 720p definition push requires no more than 30% of CPU utilization.
>
>However, for an LVB App, there must be other CPU usage, e.g. floating comments, text messaging and drop-down effects.
>
>If the overall CPU utilization exceeds 80%, video capture and coding may be affected. If the CPU utilization reaches 100%, the VJ end is already in a mess, not to mention the viewer end.

**4. Ping value of SERVER_IP**
> If the Ping value between the VJ IP and SERVER_IP is high (e.g. over 500ms), the push quality will be poor. In this case, please feedback to us.

### 2.2 SDK Push Quality Zone

The charts shown in 2.1 are from our internal data analysis system for experimental testing. If you have the same analysis demands, you can find similar charts on the quality monitoring system of [LVB Console](https://console.qcloud.com/live). Those charts are simpler and their understanding does not require too much professional audio/video fundamentals.
![](//mc.qcloudimg.com/static/img/4bf231da79ec8e45bdc4c16c927da47f/image.png)

## 3. Adjusting push parameters
If you hope to customize video encoding parameters and audio encoding parameters, you can set the Config object to realize your custom requirements. Currently, we support the following setting APIs:

| Parameter Name           |    Description                                          |   Default Value  | 
| :-------------- | :-----------------------------------------------| :------: |
| audioSampleRate|   Audio sampling rate: It refers to the count of sound signal acquisitions performed by the recording device in 1s.   |  44100   |  
| enableNAS          |   Noise suppression: After it is enabled, background noises can be filtered (effective under the sampling rate under 32000) |  Disable     |
| enableHWAcceleration|   Hardware encoding of video: After it is enabled, the maximum video acquisition of 720 p and 30 fps can be supported.   |  Enable   |  
| videoFPS     |   Video frame rate: It refers to the number of picture frames produced by the video encoder per second. Since the performance of most phones is not capable of supporting the encoding above 30 FPS, you are recommended to set FPS to 20.           |  20      |
| videoResolution|   Video resolution: Currently four kinds of 16:9 resolutions are provided to you.      |  640 * 360 |
| videoBitratePIN |   Video bit rate: It refers to the data produced by the video encoder per second, in the unit of kbps. |  800|
| enableAutoBitrate |   Bandwidth adaptation: This function can adjust the video bit rate automatically according to the current network condition. |   Disable|
| videoBitrateMax| Maximum output bit rate: This setting option can take effect only when the adaptive bit rate is enabled. |   1200|
| videoBitrateMin| Minimum output bit rate: This setting option can take effect only when the adaptive bit rate is enabled. |   800|
| videoEncodeGop | Key frame interval (unit: second): It refers to the number of seconds during which one I frame is output | 3s |
| homeOrientation| Set the rotation angle of video image, e.g., whether push of horizontal screen is needed  |   home is on the right (0) home is at the lower part (1) home is on the left (2) home is at the upper part (3)   |
| beautyFilterDepth| Beauty level: levels 1 to 9 are supported; the higher the level, the more significant the effect. 0 indicates disabling  |   Disable   |
| frontCamera | the front or rear camera by default | Front |
| watermark | Watermark picture (UIImage object) | Tencent Cloud Logo (demo)  |    
| watermarkPos | Position of the watermark picture relative to the coordinates in the upper-left corner | (0, 0)  |                                                                        

You are recommended to specify these parameter settings before enabling push, because most setting options take effect only after stream push is re-performed. The reference code is provided below:

```objectivec
//_config and _pusher are declared in member variables
....
//Initialize _config
_config = [[TXLivePushConfig alloc] init];

// Modify the parameter setting to the audio sampling rate 44100 and fixed video bit rate 800
_config.audioSampleRate = 44100;
_config.enableAutoBitrate = NO;
_config.videoBitratePIN = 800;

//Initialize _pusher
_pusher = [[TXLivePush alloc] initWithConfig:  _config];
```

## 4. If you want to process video data:
Some customers with relatively strong R&D capability will have the requirement for customizing image processing (e.g., adding subtitles), and also hope reuse the overall process of RTMP SDK. If so, you can adopt the following customizing strategy:

```objectivec
//(1) Set CustomMode to CUSTOM_MODE_VIDEO_PREPROCESS
_config.customModeType |= CUSTOM_MODE_VIDEO_PREPROCESS;
//
//(2) Set the custom video data function MyHookVideoFunc
_config.pVideoFuncPtr = MyHookVideoFunc;
```

Here, pVideoFuncPtr is a function pointer. After you specify CustomMode as VIDEO_PREPROCESS, the SDK will not preprocess the captured video by itself, but invoke the YUV processing function (MyHookVideoFunc in the example code) passed to it, where pVideoFuncPtr should observe the following function declaration:
```C
/* @brief: The prototype of video preprocessing function customized by the customer
 * @param yuv_buffer: The video YUV data, with the fixed format of YUV420 Planar
 * @param len_buffer: Data length
 * @param width:      Video width
 * @param height:     Video height
 * @return
 * @Remarks (1) This function will be called synchronously by the SDK, so you need to return synchronously the preprocessed data
 * (2) The data length after processing must be consistent with that before processing
 * (3) Or you can directly process yuv_buffer or memcpy the processed data to the memory area indicated by yuv_buffer.
 * The lifetime of this memory is managed (i.e., released) by the SDK
 */
typedef void (*PVideoProcessHookFunc)(unsigned char * yuv_buffer, int len_buffer, int width, int height);
```

> For your preprocess function, the processing time of MyHookVideoFunc cannot be too long. If the processing time of this function exceeds 50 ms, the frame rate of the video streaming pushed by the SDK cannot reach 20 FPS.

## 5. If you want to process audio data:
It is similar to video data processing, but the specific name should be changed to an audio related one.
```objectivec
//(1) Set CustomMode to  CUSTOM_MODE_AUDIO_PREPROCESS
_config.customModeType |= CUSTOM_MODE_AUDIO_PREPROCESS;
//
//(2) Set the custom video data function  MyHookAudioFunc
_config.pAudioFuncPtr = MyHookAudioFunc;
```
Here, pAudioFuncPtr should observe the following function declaration:
```C
/* @brief: The prototype of audio preprocessing function customized by the customer
 * @param pcm_buffer:    Audio PCM data
 * @param len_buffer:    Data length
 * @param sample_rate:    Sampling rate
 * @param channels:      Number of channels
 * @param bit_size:      Sampling bit size
 * @return
 * @Remarks (1) This function will be called synchronously by the SDK, so you need to return synchronously the preprocessed data
 * (2) The data length after processing must be consistent with that before processing
 *         (3) Or you can directly process pcm_buffer or memcpy the processed data to the memory area indicated by pcm_buffer.
 * The lifetime of this memory is managed (i.e., released) by the SDK
 */
typedef void (*PAudioProcessHookFunc)(unsigned char * pcm_buffer, int len_buffer,
                                          int sample_rate, int channels, int bit_size);
```

## 6. If you use the SDK only to implement push:
Some customers only hope to use the SDK to implement push. The audio and video acquisition part is controlled by their codes, and the SDK can be used to implement audio and video encoding and push.
If so, you can implement push according to the steps below:

- **Step 1 Set setCustomModeType and related parameters.**
Here, CustomMode needs to be set to CUSTOM_MODE_VIDEO_CAPTURE, which means that the SDK does not need to capture audio and video data. Meanwhile the video resolution needs to be set.
```
// (1) Set CustomMode as follows: Capture video data by yourself; the SDK is responsible for sending codes only.
_config.customModeType |= CUSTOM_MODE_VIDEO_CAPTURE;
//
// (2) Set the video encoding output resolution. The VIDEO_CAPTURE mode provides six kinds of resolutions to you.
//  VIDEO_RESOLUTION_TYPE_360_640:   The resolution of pYUVBuff must be 360 * 640
//  VIDEO_RESOLUTION_TYPE_540_960:   pYUVBuff的分辨率必须符合540*960
//  VIDEO_RESOLUTION_TYPE_720_1280:  pYUVBuff的分辨率必须符合720*1280
//  VIDEO_RESOLUTION_TYPE_640_360:   pYUVBuff的分辨率必须符合640*360
//  VIDEO_RESOLUTION_TYPE_960_540:   pYUVBuff的分辨率必须符合960*540
//  VIDEO_RESOLUTION_TYPE_1280_720:  pYUVBuff的分辨率必须符合1280*720
_config.videoResolution = VIDEO_RESOLUTION_TYPE_1280_720;
```

- **Step 2 Use sendCustomVideoData to fill video data into the SDK.**
The subsequent work is to insert your prepared video data (the currently supported formats are 420SP, 420YpCbCr, 420P, BGRA8888, RGBA8888, and NV12) into the SDK, and the subsequently work such as encoding and sending on the network should be completed by the SDK.
```
//(1) First enable push. Note that startPreview or startScreenCapture is not needed anymore.
[_txLivePublisher startPush:rtmpUrl]
//
//(2) The example code here briefs how to insert your YUV data into the SDK.
[_txLivePublisher sendCustomVideoData:  buffer dataLen:len 
          videoType:VIDEO_TYPE_420P width:720 height:1280];
```

- **Step 3. Use sendCustomPCMData to fill audio data to the SDK.**
When external capture is used for video instead, audio can be still processed through internal capture of the SDK. If you hope to replace audio capture with your own logic, you need to add CUSTOM_MODE_AUDIO_CAPTURE to the CustomMode setting option. Meanwhile, you also need to specify the key information related to the sound channel such as the audio sampling rate.
```java
// (1) Set CustomMode as follows: Capture audio data by yourself; the SDK is responsible for encoding and sending only.
_config.customModeType |= CUSTOM_MODE_AUDIO_CAPTURE;
//
// (2) Set audio encoding parameters: the audio sampling rate and number of channels
_config.audioSampleRate = 44100;
_config.audioChannels   = 1;
```
After that, invoke **sendCustomPCMData** to insert your own PCM data to the SDK.
